{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/innocent/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2022-12-09 16:23:19.567441: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-09 16:23:19.820903: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-09 16:23:19.820939: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-09 16:23:19.878854: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-09 16:23:21.579517: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-09 16:23:21.579710: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-09 16:23:21.579733: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-12-09 16:23:23.086143: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-12-09 16:23:23.086192: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-09 16:23:23.086222: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (parrot): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import spacy\n",
    "import warnings\n",
    "from spacy import displacy\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_columns\",None)\n",
    "pd.set_option(\"display.max_rows\",None)\n",
    "pd.set_option(\"display.max_colwidth\",2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-09 16:23:26.787320: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-09 16:23:27.055192: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-09 16:23:27.055226: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-09 16:23:27.101924: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-09 16:23:28.189121: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-09 16:23:28.189239: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-09 16:23:28.189267: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-12-09 16:23:30.437013: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-12-09 16:23:30.437050: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-09 16:23:30.437084: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (parrot): /proc/driver/nvidia/version does not exist\n",
      "\u001b[38;5;4mℹ Saving to output directory: .\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2022-12-09 16:23:31,897] [INFO] Set up nlp object from config\n",
      "[2022-12-09 16:23:31,922] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-12-09 16:23:31,935] [INFO] Created vocabulary\n",
      "[2022-12-09 16:23:31,938] [INFO] Finished initializing nlp object\n",
      "[2022-12-09 16:23:36,603] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     34.67    0.02    0.18    0.01    0.00\n",
      "  0     200         48.42   1504.13   80.15   89.41   72.63    0.80\n",
      "  0     400         51.38    806.99   84.42   92.13   77.90    0.84\n",
      "  0     600         55.91    878.54   85.47   91.44   80.23    0.85\n",
      "  1     800        950.55    956.70   88.58   89.71   87.49    0.89\n",
      "  1    1000        536.60    874.06   90.98   90.64   91.32    0.91\n",
      "  2    1200         84.95    886.85   91.91   91.54   92.29    0.92\n",
      "  2    1400        118.11    832.54   93.15   93.06   93.23    0.93\n",
      "  3    1600        171.18    829.61   93.43   92.80   94.07    0.93\n",
      "  4    1800        146.75    719.00   94.56   95.51   93.62    0.95\n",
      "  5    2000        205.65    737.58   95.54   96.33   94.76    0.96\n",
      "  7    2200        248.26    581.10   95.08   95.20   94.95    0.95\n",
      "  9    2400        270.44    550.52   95.49   95.58   95.40    0.95\n",
      " 11    2600        287.46    434.02   96.01   96.50   95.53    0.96\n",
      " 13    2800        286.20    361.36   95.90   96.25   95.55    0.96\n",
      " 15    3000        307.66    361.45   96.16   96.48   95.83    0.96\n",
      " 16    3200        383.40    279.37   96.13   96.55   95.70    0.96\n",
      " 18    3400        439.37    304.92   96.04   96.30   95.78    0.96\n",
      " 20    3600        407.22    256.08   96.10   96.98   95.23    0.96\n",
      " 22    3800        524.86    261.91   95.95   96.29   95.60    0.96\n",
      " 24    4000        418.77    206.81   96.06   96.77   95.36    0.96\n",
      " 26    4200        497.94    221.52   95.99   96.37   95.62    0.96\n",
      " 28    4400        473.85    200.64   95.99   96.43   95.57    0.96\n",
      " 30    4600        647.05    191.81   95.64   95.30   95.99    0.96\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "model-last\n"
     ]
    }
   ],
   "source": [
    "! python3 -m spacy train config.cfg --output ./ --paths.train ./Training_data.spacy --paths.dev ./Testing_data.spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=spacy.load('./model-best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_text = \"Please read below!! Another devastating fire has hit Northern California, people need help, whatever you can give, or anyway you can help, please do\\u1f64F!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tweet_id': '',\n",
       " 'location_mentions': [{'text': 'California',\n",
       "   'start_offset': 62,\n",
       "   'end_offset': 72}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_located_list=\"\"\n",
    "twitter_id=\"\"\n",
    "a=twitter_text\n",
    "list_locations=[]\n",
    "dict_list = []\n",
    "\n",
    "def find_index(sentence,word):\n",
    "    str2=word\n",
    "    str1=sentence\n",
    "    start_index=str1.index(str2)\n",
    "    length_word=len(str2)\n",
    "    end_index=start_index+length_word\n",
    "    start=start_index\n",
    "    end=end_index\n",
    "    return start,end\n",
    "\n",
    "test_preds=model(twitter_text)\n",
    "for entity in test_preds.ents:\n",
    "    if entity.label_=='Location':\n",
    "        list_locations.append(entity.text)\n",
    "    \n",
    "for b in list_locations:\n",
    "    data_located_Dict={}\n",
    "    data_located_Dict['text']=b\n",
    "    start_index,end_index=find_index(a,b) \n",
    "    data_located_Dict['start_offset']=start_index\n",
    "    data_located_Dict['end_offset']=end_index\n",
    "    dict_list.append(data_located_Dict)\n",
    "    \n",
    "#Final Results\n",
    "Model_Results={\"tweet_id\":twitter_id,\"location_mentions\":dict_list}\n",
    "Model_Results "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
