{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import spacy\n",
    "import warnings\n",
    "from spacy import displacy\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_columns\",None)\n",
    "pd.set_option(\"display.max_rows\",None)\n",
    "pd.set_option(\"display.max_colwidth\",2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-11 18:19:57.769565: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-11 18:19:58.048952: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-11 18:19:58.048987: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-11 18:19:58.096457: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-11 18:19:59.214573: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-11 18:19:59.214670: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-11 18:19:59.214685: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-12-11 18:20:01.518357: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-12-11 18:20:01.518394: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-11 18:20:01.518428: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (parrot): /proc/driver/nvidia/version does not exist\n",
      "\u001b[38;5;4mℹ Saving to output directory: .\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2022-12-11 18:20:02,809] [INFO] Set up nlp object from config\n",
      "[2022-12-11 18:20:02,836] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-12-11 18:20:02,846] [INFO] Created vocabulary\n",
      "[2022-12-11 18:20:02,849] [INFO] Finished initializing nlp object\n",
      "[2022-12-11 18:20:12,601] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     31.67    0.01    0.96    0.01    0.00\n",
      "  0     200         48.70   1498.03   72.40   76.82   68.47    0.72\n",
      "  0     400         51.42    832.70   74.75   94.22   61.95    0.75\n",
      "  0     600         54.59    799.44   80.67   92.01   71.81    0.81\n",
      "  0     800         76.66    952.57   78.22   92.85   67.57    0.78\n",
      "  0    1000        178.35   1063.98   83.44   93.93   75.06    0.83\n",
      "  0    1200        102.70   1225.12   86.02   86.57   85.47    0.86\n",
      "  1    1400        216.79   1197.36   87.23   91.81   83.08    0.87\n",
      "  1    1600        114.63   1299.67   87.69   88.61   86.79    0.88\n",
      "  2    1800        175.09   1568.34   88.04   89.64   86.49    0.88\n",
      "  2    2000        159.79   1573.21   89.06   92.67   85.72    0.89\n",
      "  3    2200        189.85   1513.85   89.55   91.97   87.26    0.90\n",
      "  4    2400        963.62   1698.99   90.15   93.42   87.10    0.90\n",
      "  5    2600        249.59   1379.65   91.68   94.64   88.89    0.92\n",
      "  6    2800        230.24   1263.14   91.53   94.98   88.33    0.92\n",
      "  7    3000        222.84   1156.70   91.81   95.47   88.43    0.92\n",
      "  8    3200        215.40   1018.64   91.97   95.69   88.52    0.92\n",
      "  8    3400        253.08    880.91   91.83   94.31   89.47    0.92\n",
      "  9    3600        249.04    766.17   91.43   94.72   88.36    0.91\n",
      " 10    3800        286.87    750.58   92.44   94.20   90.75    0.92\n",
      " 11    4000        298.38    703.49   92.01   94.00   90.11    0.92\n",
      " 12    4200        267.08    616.62   92.44   95.26   89.78    0.92\n",
      " 13    4400        255.57    641.05   92.36   95.08   89.78    0.92\n",
      " 14    4600        257.14    603.70   92.18   94.61   89.87    0.92\n",
      " 15    4800        245.60    479.56   92.42   95.36   89.65    0.92\n",
      " 16    5000        266.39    554.59   92.43   95.22   89.80    0.92\n",
      " 17    5200        299.76    504.54   92.75   95.78   89.90    0.93\n",
      " 18    5400        322.96    456.38   92.44   95.64   89.45    0.92\n",
      " 18    5600        321.06    443.57   92.55   96.39   89.01    0.93\n",
      " 19    5800        378.57    408.30   92.87   96.34   89.64    0.93\n",
      " 20    6000        371.07    421.69   92.26   94.70   89.93    0.92\n",
      " 21    6200        453.83    404.68   92.52   94.94   90.22    0.93\n",
      " 22    6400        471.04    424.24   92.94   96.03   90.05    0.93\n",
      " 23    6600        426.39    343.55   92.48   94.93   90.17    0.92\n",
      " 24    6800        506.69    346.77   92.28   95.65   89.13    0.92\n",
      " 25    7000        469.21    362.24   93.42   97.07   90.04    0.93\n",
      " 26    7200        530.38    323.78   92.97   96.26   89.89    0.93\n",
      " 27    7400        490.14    338.92   93.13   96.98   89.58    0.93\n",
      " 28    7600        537.16    312.27   93.01   96.40   89.85    0.93\n",
      " 28    7800        566.31    312.02   92.51   95.10   90.05    0.93\n",
      " 29    8000        639.52    258.53   92.93   96.06   90.00    0.93\n",
      " 30    8200        713.58    272.65   92.61   95.32   90.06    0.93\n",
      " 31    8400        788.78    281.08   92.86   96.19   89.76    0.93\n",
      " 32    8600        743.78    276.12   92.73   95.69   89.94    0.93\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "model-last\n"
     ]
    }
   ],
   "source": [
    "! python3 -m spacy train config.cfg --output ./ --paths.train ./Training_data.spacy --paths.dev ./Testing_data.spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=spacy.load('./model-best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_text = \"Please read below!! Another devastating fire has hit Northern California, people need help, whatever you can give, or anyway you can help, please do\\u1f64F!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tweet_id': '',\n",
       " 'location_mentions': [{'text': 'California',\n",
       "   'start_offset': 62,\n",
       "   'end_offset': 72}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_located_list=\"\"\n",
    "twitter_id=\"\"\n",
    "a=twitter_text\n",
    "list_locations=[]\n",
    "dict_list = []\n",
    "\n",
    "def find_index(sentence,word):\n",
    "    str2=word\n",
    "    str1=sentence\n",
    "    start_index=str1.index(str2)\n",
    "    length_word=len(str2)\n",
    "    end_index=start_index+length_word\n",
    "    start=start_index\n",
    "    end=end_index\n",
    "    return start,end\n",
    "\n",
    "test_preds=model(twitter_text)\n",
    "for entity in test_preds.ents:\n",
    "    if entity.label_=='Location':\n",
    "        list_locations.append(entity.text)\n",
    "    \n",
    "for b in list_locations:\n",
    "    data_located_Dict={}\n",
    "    data_located_Dict['text']=b\n",
    "    start_index,end_index=find_index(a,b) \n",
    "    data_located_Dict['start_offset']=start_index\n",
    "    data_located_Dict['end_offset']=end_index\n",
    "    dict_list.append(data_located_Dict)\n",
    "    \n",
    "#Final Results\n",
    "Model_Results={\"tweet_id\":twitter_id,\"location_mentions\":dict_list}\n",
    "Model_Results "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
